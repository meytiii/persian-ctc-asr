{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cF-y3xLtcSvI"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import librosa\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, LSTM, Dense, Masking, TimeDistributed, Activation, Bidirectional, Lambda, Dropout, BatchNormalization\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.utils import plot_model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download and unzip dataset\n",
        "import gdown\n",
        "\n",
        "url = 'https://drive.google.com/uc?id=1jyvhdZHn0s5Owkr21k5Ff-c96sIQLtEu'\n",
        "output = 'all_wav.zip'\n",
        "gdown.download(url, output, quiet=False)\n",
        "!unzip -q 'all_wav.zip' -d '/content/all_wav'\n",
        "\n",
        "url = 'https://drive.google.com/uc?id=1vqvn0F0YYhEFbzLgP9wJ36vyInUnO5b5'\n",
        "output = 'dataset.csv'\n",
        "gdown.download(url, output, quiet=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 738
        },
        "id": "iEE7XEjQcV2E",
        "outputId": "4c3f217c-f7b8-45a2-9279-6576aa1d8b94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileURLRetrievalError",
          "evalue": "Failed to retrieve file url:\n\n\tToo many users have viewed or downloaded this file recently. Please\n\ttry accessing the file again later. If the file you are trying to\n\taccess is particularly large or is shared with many people, it may\n\ttake up to 24 hours to be able to view or download the file. If you\n\tstill can't access a file after 24 hours, contact your domain\n\tadministrator.\n\nYou may still be able to access the file from the browser:\n\n\thttps://drive.google.com/uc?id=1jyvhdZHn0s5Owkr21k5Ff-c96sIQLtEu\n\nbut Gdown can't. Please check connections and permissions.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileURLRetrievalError\u001b[0m                     Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gdown/download.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(url, output, quiet, proxy, speed, use_cookies, verify, id, fuzzy, resume, format, user_agent, log_messages)\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m             \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_url_from_gdrive_confirmation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mFileURLRetrievalError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gdown/download.py\u001b[0m in \u001b[0;36mget_url_from_gdrive_confirmation\u001b[0;34m(contents)\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mFileURLRetrievalError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileURLRetrievalError\u001b[0m: Too many users have viewed or downloaded this file recently. Please try accessing the file again later. If the file you are trying to access is particularly large or is shared with many people, it may take up to 24 hours to be able to view or download the file. If you still can't access a file after 24 hours, contact your domain administrator.",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mFileURLRetrievalError\u001b[0m                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-7c4fba339dda>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'https://drive.google.com/uc?id=1jyvhdZHn0s5Owkr21k5Ff-c96sIQLtEu'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'all_wav.zip'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mgdown\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquiet\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"unzip -q 'all_wav.zip' -d '/content/all_wav'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gdown/download.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(url, output, quiet, proxy, speed, use_cookies, verify, id, fuzzy, resume, format, user_agent, log_messages)\u001b[0m\n\u001b[1;32m    262\u001b[0m                 \u001b[0murl_origin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m             )\n\u001b[0;32m--> 264\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mFileURLRetrievalError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0mfilename_from_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileURLRetrievalError\u001b[0m: Failed to retrieve file url:\n\n\tToo many users have viewed or downloaded this file recently. Please\n\ttry accessing the file again later. If the file you are trying to\n\taccess is particularly large or is shared with many people, it may\n\ttake up to 24 hours to be able to view or download the file. If you\n\tstill can't access a file after 24 hours, contact your domain\n\tadministrator.\n\nYou may still be able to access the file from the browser:\n\n\thttps://drive.google.com/uc?id=1jyvhdZHn0s5Owkr21k5Ff-c96sIQLtEu\n\nbut Gdown can't. Please check connections and permissions."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "df = pd.read_csv('/content/dataset.csv')\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "id": "Jt1htHDTdQTc",
        "outputId": "aa6efa31-5650-4b8d-f9e3-4c4d02441385"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                           wav_filename  wav_filesize  \\\n",
              "0  ./all_wav/Tehran_SayeRoshan0_101.wav         83044   \n",
              "1  ./all_wav/Tehran_SayeRoshan0_105.wav         54468   \n",
              "2  ./all_wav/Tehran_SayeRoshan0_107.wav        136036   \n",
              "3  ./all_wav/Tehran_SayeRoshan0_108.wav        106788   \n",
              "4  ./all_wav/Tehran_SayeRoshan0_109.wav        170020   \n",
              "\n",
              "                                         transcript  confidence_level  \n",
              "0                            اتفاقاتی که ندیده بودم          0.927557  \n",
              "1                                              مسجد          0.927557  \n",
              "2                 جمع شدن مسلمین برای نمازهای جماعت          0.864152  \n",
              "3                          همیشه برای محمدرضا پهلوی          0.927557  \n",
              "4  چه زمانی در کسوت شاه ایران نوکری اجانب را می‌کرد          0.854824  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bff9d2c8-7460-4a13-86fb-4d60e54b3167\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>wav_filename</th>\n",
              "      <th>wav_filesize</th>\n",
              "      <th>transcript</th>\n",
              "      <th>confidence_level</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>./all_wav/Tehran_SayeRoshan0_101.wav</td>\n",
              "      <td>83044</td>\n",
              "      <td>اتفاقاتی که ندیده بودم</td>\n",
              "      <td>0.927557</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>./all_wav/Tehran_SayeRoshan0_105.wav</td>\n",
              "      <td>54468</td>\n",
              "      <td>مسجد</td>\n",
              "      <td>0.927557</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>./all_wav/Tehran_SayeRoshan0_107.wav</td>\n",
              "      <td>136036</td>\n",
              "      <td>جمع شدن مسلمین برای نمازهای جماعت</td>\n",
              "      <td>0.864152</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>./all_wav/Tehran_SayeRoshan0_108.wav</td>\n",
              "      <td>106788</td>\n",
              "      <td>همیشه برای محمدرضا پهلوی</td>\n",
              "      <td>0.927557</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>./all_wav/Tehran_SayeRoshan0_109.wav</td>\n",
              "      <td>170020</td>\n",
              "      <td>چه زمانی در کسوت شاه ایران نوکری اجانب را می‌کرد</td>\n",
              "      <td>0.854824</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bff9d2c8-7460-4a13-86fb-4d60e54b3167')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-bff9d2c8-7460-4a13-86fb-4d60e54b3167 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-bff9d2c8-7460-4a13-86fb-4d60e54b3167');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-254f0a6a-86b8-49fc-a3e1-a2447f5e8a63\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-254f0a6a-86b8-49fc-a3e1-a2447f5e8a63')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-254f0a6a-86b8-49fc-a3e1-a2447f5e8a63 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 24366,\n  \"fields\": [\n    {\n      \"column\": \"wav_filename\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 24366,\n        \"samples\": [\n          \"./all_wav/Varzesh_ShabHayeNarenji44_72.wav\",\n          \"./all_wav/Varzesh_SakooyeMann10_183.wav\",\n          \"./all_wav/Tehran_YekTehranDoa0_241.wav\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"wav_filesize\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 78651,\n        \"min\": 50020,\n        \"max\": 399780,\n        \"num_unique_values\": 7819,\n        \"samples\": [\n          105700,\n          144580,\n          157316\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"transcript\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 21540,\n        \"samples\": [\n          \"\\u06cc\\u0639\\u0646\\u06cc \\u062e\\u0648\\u062f\\u062a \\u0645\\u06cc \\u0628\\u0631\\u06cc\\u0632 \\u062a\\u0648 \\u0645\\u06cc\\u0634\\u0648\\u0631\\u06cc\",\n          \"\\u062f\\u0631 \\u062c\\u0644\\u0633\\u0627\\u062a\",\n          \"\\u0647\\u062f\\u0641 \\u0647\\u0627\\u06cc \\u0645\\u0634\\u062e\\u0635 \\u0628\\u0647 \\u0622\\u0646\\u0647\\u0627 \\u062f\\u0627\\u062f\\u0647\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"confidence_level\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.04787249721394445,\n        \"min\": 0.79001349,\n        \"max\": 0.92755735,\n        \"num_unique_values\": 18100,\n        \"samples\": [\n          0.79745895,\n          0.83093834,\n          0.84155327\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Update paths for WAV files\n",
        "df['wav_filename'] = df['wav_filename'].apply(lambda x: x.replace('./all_wav/', '/content/all_wav/all_wav/'))\n",
        "\n",
        "# Filter dataset to include only existing WAV files\n",
        "df = df[df['wav_filename'].apply(os.path.isfile)]\n",
        "\n",
        "# Character map for Persian characters\n",
        "char_map_str = \"\"\"\n",
        "' 0\n",
        "<SPACE> 1\n",
        "ا 2\n",
        "ب 3\n",
        "پ 4\n",
        "ت 5\n",
        "ث 6\n",
        "ج 7\n",
        "چ 8\n",
        "ح 9\n",
        "خ 10\n",
        "د 11\n",
        "ذ 12\n",
        "ر 13\n",
        "ز 14\n",
        "ژ 15\n",
        "س 16\n",
        "ش 17\n",
        "ص 18\n",
        "ض 19\n",
        "ط 20\n",
        "ظ 21\n",
        "ع 22\n",
        "غ 23\n",
        "ف 24\n",
        "ق 25\n",
        "ک 26\n",
        "گ 27\n",
        "ل 28\n",
        "م 29\n",
        "ن 30\n",
        "و 31\n",
        "ه 32\n",
        "ی 33\n",
        "، 34\n",
        "؟ 35\n",
        "\"\"\"\n",
        "char_map = {}\n",
        "index_map = {}\n",
        "for line in char_map_str.strip().split('\\n'):\n",
        "    ch, index = line.split()\n",
        "    char_map[ch] = int(index)\n",
        "    index_map[int(index)] = ch\n",
        "index_map[1] = ' '\n",
        "\n",
        "# Ensure space character is in char_map\n",
        "char_map[' '] = char_map['<SPACE>']\n",
        "\n",
        "# Audio processing functions\n",
        "def load_audio(file_path, sr=16000):\n",
        "    audio, _ = librosa.load(file_path, sr=sr)\n",
        "    return audio\n",
        "\n",
        "def extract_features(audio, n_mfcc=20, sr=16000):\n",
        "    mfcc_features = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=n_mfcc)\n",
        "    delta_mfcc = librosa.feature.delta(mfcc_features)\n",
        "    combined = np.vstack((mfcc_features, delta_mfcc)).T\n",
        "    return combined\n",
        "\n",
        "def add_noise(audio, noise_factor=0.005):\n",
        "    noise = np.random.randn(len(audio))\n",
        "    augmented_audio = audio + noise_factor * noise\n",
        "    augmented_audio = augmented_audio.astype(type(audio[0]))\n",
        "    return augmented_audio\n",
        "\n",
        "def shift_time(audio, shift_max=0.2):\n",
        "    shift = np.random.randint(int(shift_max * 16000))\n",
        "    if np.random.rand() > 0.5:\n",
        "        shift = -shift\n",
        "    augmented_audio = np.roll(audio, shift)\n",
        "    if shift > 0:\n",
        "        augmented_audio[:shift] = 0\n",
        "    else:\n",
        "        augmented_audio[shift:] = 0\n",
        "    return augmented_audio\n",
        "\n",
        "def pitch_shift(audio, sr=16000, n_steps=2.0):\n",
        "    return librosa.effects.pitch_shift(audio, sr=sr, n_steps=n_steps)\n",
        "\n",
        "def stretch_audio(audio, rate=0.8):\n",
        "    return librosa.effects.time_stretch(y=audio, rate=rate)\n",
        "\n",
        "# Prepare the dataset\n",
        "X = []\n",
        "y = []\n",
        "input_lengths = []\n",
        "label_lengths = []\n",
        "\n",
        "augment_functions = [add_noise, shift_time, pitch_shift, stretch_audio]\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "    audio_path = row['wav_filename']\n",
        "    audio = load_audio(audio_path)\n",
        "\n",
        "    for augment_func in augment_functions:\n",
        "        augmented_audio = augment_func(audio)\n",
        "        features = extract_features(augmented_audio)\n",
        "        X.append(features)\n",
        "        input_lengths.append(features.shape[0])\n",
        "        label = [char_map.get(c, char_map[' ']) for c in row['transcript']]\n",
        "        y.append(label)\n",
        "        label_lengths.append(len(label))\n",
        "\n",
        "if len(X) == 0 or len(y) == 0:\n",
        "    raise ValueError(\"No valid audio files were found. Please check the dataset and the paths.\")\n",
        "\n",
        "X = tf.keras.preprocessing.sequence.pad_sequences(X, padding='post', dtype='float32')\n",
        "y = tf.keras.preprocessing.sequence.pad_sequences(y, padding='post', value=-1)\n",
        "\n",
        "# Save the augmented data\n",
        "np.save('/content/X_augmented.npy', X)\n",
        "np.save('/content/y_augmented.npy', y)\n",
        "np.save('/content/input_lengths_augmented.npy', input_lengths)\n",
        "np.save('/content/label_lengths_augmented.npy', label_lengths)"
      ],
      "metadata": {
        "id": "3xnzqau3cX3w",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "outputId": "0b4fb94b-5950-4930-c55f-564e4702be4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-45117e1fa3bb>\u001b[0m in \u001b[0;36m<cell line: 99>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0maugment_func\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maugment_functions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0maugmented_audio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maugment_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maugmented_audio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0minput_lengths\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-45117e1fa3bb>\u001b[0m in \u001b[0;36mextract_features\u001b[0;34m(audio, n_mfcc, sr)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mextract_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_mfcc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m     \u001b[0mmfcc_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmfcc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maudio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_mfcc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_mfcc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m     \u001b[0mdelta_mfcc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmfcc_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0mcombined\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmfcc_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelta_mfcc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/librosa/feature/spectral.py\u001b[0m in \u001b[0;36mmfcc\u001b[0;34m(y, sr, S, n_mfcc, dct_type, norm, lifter, **kwargs)\u001b[0m\n\u001b[1;32m   1987\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mS\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1988\u001b[0m         \u001b[0;31m# multichannel behavior may be different due to relative noise floor differences between channels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1989\u001b[0;31m         \u001b[0mS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpower_to_db\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmelspectrogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1990\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1991\u001b[0m     M: np.ndarray = scipy.fftpack.dct(S, axis=-2, type=dct_type, norm=norm)[\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/librosa/feature/spectral.py\u001b[0m in \u001b[0;36mmelspectrogram\u001b[0;34m(y, sr, S, n_fft, hop_length, win_length, window, center, pad_mode, power, **kwargs)\u001b[0m\n\u001b[1;32m   2128\u001b[0m     \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Mel-frequency spectrogram'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2129\u001b[0m     \"\"\"\n\u001b[0;32m-> 2130\u001b[0;31m     S, n_fft = _spectrogram(\n\u001b[0m\u001b[1;32m   2131\u001b[0m         \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2132\u001b[0m         \u001b[0mS\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/librosa/core/spectrum.py\u001b[0m in \u001b[0;36m_spectrogram\u001b[0;34m(y, S, n_fft, hop_length, power, win_length, window, center, pad_mode)\u001b[0m\n\u001b[1;32m   2943\u001b[0m         S = (\n\u001b[1;32m   2944\u001b[0m             np.abs(\n\u001b[0;32m-> 2945\u001b[0;31m                 stft(\n\u001b[0m\u001b[1;32m   2946\u001b[0m                     \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2947\u001b[0m                     \u001b[0mn_fft\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_fft\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/librosa/core/spectrum.py\u001b[0m in \u001b[0;36mstft\u001b[0;34m(y, n_fft, hop_length, win_length, window, center, dtype, pad_mode, out)\u001b[0m\n\u001b[1;32m    385\u001b[0m         \u001b[0mbl_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbl_s\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mn_columns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_frames\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m         stft_matrix[..., bl_s + off_start : bl_t + off_start] = fft.rfft(\n\u001b[0m\u001b[1;32m    388\u001b[0m             \u001b[0mfft_window\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0my_frames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbl_s\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbl_t\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/fft/_pocketfft.py\u001b[0m in \u001b[0;36mrfft\u001b[0;34m(a, n, axis, norm)\u001b[0m\n\u001b[1;32m    407\u001b[0m         \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m     \u001b[0minv_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_forward_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_raw_fft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minv_norm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/fft/_pocketfft.py\u001b[0m in \u001b[0;36m_raw_fft\u001b[0;34m(a, n, axis, is_real, is_forward, inv_norm)\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mswapaxes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpfi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_real\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_forward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfct\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mswapaxes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown\n",
        "# Download the augmented data from Google Drive\n",
        "file_urls = {\n",
        "    'X_augmented.npy': 'https://drive.google.com/uc?id=1-5QQGFBQuL4AO9XTMwb4o7TlTpsoG9M4',\n",
        "    'y_augmented.npy': 'https://drive.google.com/uc?id=1-7-Oh7Mj2qaVNr8eBAMhvzMubhDoLsSX',\n",
        "    'input_lengths_augmented.npy': 'https://drive.google.com/uc?id=1-7yhidCIPb2EdKN7ZDweHOf4Q9sNd63a',\n",
        "    'label_lengths_augmented.npy': 'https://drive.google.com/uc?id=1-77poJQcMc1V5GqnHLazIfjZcvDbvkVi'\n",
        "}\n",
        "\n",
        "for file_name, file_url in file_urls.items():\n",
        "    gdown.download(file_url, f'/content/{file_name}', quiet=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uA6NREYlQhZU",
        "outputId": "a35ccc44-b7b8-49a7-92b7-7c282b28d55f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1-5QQGFBQuL4AO9XTMwb4o7TlTpsoG9M4\n",
            "From (redirected): https://drive.google.com/uc?id=1-5QQGFBQuL4AO9XTMwb4o7TlTpsoG9M4&confirm=t&uuid=9a5a8bd1-f35d-49cc-a9d0-3cd999efc7e8\n",
            "To: /content/X_augmented.npy\n",
            "100%|██████████| 7.61G/7.61G [00:55<00:00, 138MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-7-Oh7Mj2qaVNr8eBAMhvzMubhDoLsSX\n",
            "To: /content/y_augmented.npy\n",
            "100%|██████████| 67.8M/67.8M [00:00<00:00, 68.9MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-7yhidCIPb2EdKN7ZDweHOf4Q9sNd63a\n",
            "To: /content/input_lengths_augmented.npy\n",
            "100%|██████████| 780k/780k [00:00<00:00, 111MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-77poJQcMc1V5GqnHLazIfjZcvDbvkVi\n",
            "To: /content/label_lengths_augmented.npy\n",
            "100%|██████████| 780k/780k [00:00<00:00, 82.6MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define character map\n",
        "char_map_str = \"\"\"\n",
        "' 0\n",
        "<SPACE> 1\n",
        "ا 2\n",
        "ب 3\n",
        "پ 4\n",
        "ت 5\n",
        "ث 6\n",
        "ج 7\n",
        "چ 8\n",
        "ح 9\n",
        "خ 10\n",
        "د 11\n",
        "ذ 12\n",
        "ر 13\n",
        "ز 14\n",
        "ژ 15\n",
        "س 16\n",
        "ش 17\n",
        "ص 18\n",
        "ض 19\n",
        "ط 20\n",
        "ظ 21\n",
        "ع 22\n",
        "غ 23\n",
        "ف 24\n",
        "ق 25\n",
        "ک 26\n",
        "گ 27\n",
        "ل 28\n",
        "م 29\n",
        "ن 30\n",
        "و 31\n",
        "ه 32\n",
        "ی 33\n",
        "، 34\n",
        "؟ 35\n",
        "\"\"\"\n",
        "char_map = {}\n",
        "index_map = {}\n",
        "for line in char_map_str.strip().split('\\n'):\n",
        "    ch, index = line.split()\n",
        "    char_map[ch] = int(index)\n",
        "    index_map[int(index)] = ch\n",
        "index_map[1] = ' '\n",
        "\n",
        "# Ensure space character is in char_map\n",
        "char_map[' '] = char_map['<SPACE>']"
      ],
      "metadata": {
        "id": "Oqfht2t59lg2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the augmented data\n",
        "X = np.load('/content/X_augmented.npy', mmap_mode='r')\n",
        "y = np.load('/content/y_augmented.npy', mmap_mode='r')\n",
        "input_lengths = np.load('/content/input_lengths_augmented.npy', allow_pickle=True, mmap_mode='r')\n",
        "label_lengths = np.load('/content/label_lengths_augmented.npy', allow_pickle=True, mmap_mode='r')\n",
        "\n",
        "# Ensure input_lengths and label_lengths are lists\n",
        "input_lengths = list(input_lengths)\n",
        "label_lengths = list(label_lengths)\n",
        "\n",
        "# Define the model with increased LSTM units to 256\n",
        "input_data = Input(name='the_input', shape=(None, 40))\n",
        "masking_layer = Masking(mask_value=0.0)(input_data)\n",
        "bilstm_layer_1 = Bidirectional(LSTM(256, return_sequences=True))(masking_layer)\n",
        "batch_norm_1 = BatchNormalization()(bilstm_layer_1)\n",
        "dropout_1 = Dropout(0.3)(batch_norm_1)\n",
        "bilstm_layer_2 = Bidirectional(LSTM(256, return_sequences=True))(dropout_1)\n",
        "batch_norm_2 = BatchNormalization()(bilstm_layer_2)\n",
        "dropout_2 = Dropout(0.3)(batch_norm_2)\n",
        "time_dense = TimeDistributed(Dense(len(char_map) + 1))(dropout_2)\n",
        "y_pred = Activation('softmax', name='activation')(time_dense)\n",
        "\n",
        "# Define the CTC loss function\n",
        "def ctc_lambda_func(args):\n",
        "    y_pred, labels, input_length, label_length = args\n",
        "    return tf.keras.backend.ctc_batch_cost(labels, y_pred, input_length, label_length)\n",
        "\n",
        "# Compile the model with CTC loss\n",
        "labels = Input(name='the_labels', shape=[None], dtype='float32')\n",
        "input_length = Input(name='input_length', shape=[1], dtype='int64')\n",
        "label_length = Input(name='label_length', shape=[1], dtype='int64')\n",
        "loss_out = Lambda(ctc_lambda_func, output_shape=(1,), name='ctc')([y_pred, labels, input_length, label_length])\n",
        "\n",
        "model = Model(inputs=[input_data, labels, input_length, label_length], outputs=loss_out)\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005), loss={'ctc': lambda y_true, y_pred: y_pred})\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "X_train, X_val, y_train, y_val, input_length_train, input_length_val, label_length_train, label_length_val = train_test_split(\n",
        "    X, y, input_lengths, label_lengths, test_size=0.2, random_state=42)\n",
        "\n",
        "# Data generator\n",
        "def data_generator(X, y, input_lengths, label_lengths, batch_size=16):\n",
        "    while True:\n",
        "        for i in range(0, len(X), batch_size):\n",
        "            X_batch = X[i:i+batch_size]\n",
        "            y_batch = y[i:i+batch_size]\n",
        "            input_lengths_batch = input_lengths[i:i+batch_size]\n",
        "            label_lengths_batch = label_lengths[i:i+batch_size]\n",
        "            yield (\n",
        "                {\n",
        "                    'the_input': np.array(X_batch),\n",
        "                    'the_labels': np.array(y_batch),\n",
        "                    'input_length': np.array(input_lengths_batch),\n",
        "                    'label_length': np.array(label_lengths_batch)\n",
        "                },\n",
        "                {'ctc': np.zeros([len(X_batch)])}\n",
        "            )\n",
        "\n",
        "train_gen = data_generator(X_train, y_train, input_length_train, label_length_train, batch_size=16)\n",
        "val_gen = data_generator(X_val, y_val, input_length_val, label_length_val, batch_size=16)\n",
        "\n",
        "steps_per_epoch = len(X_train) // 16\n",
        "validation_steps = len(X_val) // 16\n",
        "\n",
        "# Define callbacks\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "model_checkpoint = ModelCheckpoint('/content/asr_best_model.keras', monitor='val_loss', save_best_only=True)\n",
        "\n",
        "# Train the model\n",
        "model.fit(train_gen, steps_per_epoch=steps_per_epoch, epochs=30, validation_data=val_gen, validation_steps=validation_steps, callbacks=[early_stopping, model_checkpoint])\n",
        "\n",
        "# Save the final model\n",
        "model.save('/content/asr_model.keras')"
      ],
      "metadata": {
        "id": "u5ThnowzkwGg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40efcd5d-8cc1-4bd8-8033-deada18a9cf9"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "4873/4873 [==============================] - ETA: 0s - loss: 91.7101"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/saving/serialization_lib.py:403: UserWarning: The object being serialized includes a `lambda`. This is unsafe. In order to reload the object, you will have to pass `safe_mode=False` to the loading function. Please avoid using `lambda` in the future, and use named Python functions instead. This is the `lambda` being serialized: model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005), loss={'ctc': lambda y_true, y_pred: y_pred})\n",
            "\n",
            "  return {key: serialize_keras_object(value) for key, value in obj.items()}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4873/4873 [==============================] - 584s 115ms/step - loss: 91.7101 - val_loss: 74.1926\n",
            "Epoch 2/30\n",
            "4873/4873 [==============================] - 572s 117ms/step - loss: 72.1144 - val_loss: 65.4814\n",
            "Epoch 3/30\n",
            "4873/4873 [==============================] - 557s 114ms/step - loss: 65.9308 - val_loss: 61.2314\n",
            "Epoch 4/30\n",
            "4873/4873 [==============================] - 549s 113ms/step - loss: 62.1016 - val_loss: 58.5353\n",
            "Epoch 5/30\n",
            "4873/4873 [==============================] - 537s 110ms/step - loss: 59.2104 - val_loss: 56.3387\n",
            "Epoch 6/30\n",
            "4873/4873 [==============================] - 538s 110ms/step - loss: 56.9129 - val_loss: 54.5852\n",
            "Epoch 7/30\n",
            "4873/4873 [==============================] - 534s 110ms/step - loss: 55.0149 - val_loss: 53.5075\n",
            "Epoch 8/30\n",
            "4873/4873 [==============================] - 536s 110ms/step - loss: 53.4351 - val_loss: 52.2766\n",
            "Epoch 9/30\n",
            "4873/4873 [==============================] - 530s 109ms/step - loss: 52.3276 - val_loss: 51.2209\n",
            "Epoch 10/30\n",
            "4873/4873 [==============================] - 530s 109ms/step - loss: 50.9162 - val_loss: 50.3916\n",
            "Epoch 11/30\n",
            "4873/4873 [==============================] - 533s 109ms/step - loss: 49.8740 - val_loss: 51.0036\n",
            "Epoch 12/30\n",
            "4873/4873 [==============================] - 545s 112ms/step - loss: 49.2796 - val_loss: 49.2875\n",
            "Epoch 13/30\n",
            "4873/4873 [==============================] - 540s 111ms/step - loss: 48.1727 - val_loss: 48.6746\n",
            "Epoch 14/30\n",
            "4873/4873 [==============================] - 532s 109ms/step - loss: 47.3777 - val_loss: 47.8543\n",
            "Epoch 15/30\n",
            "4873/4873 [==============================] - 528s 108ms/step - loss: 46.6414 - val_loss: 47.6034\n",
            "Epoch 16/30\n",
            "4873/4873 [==============================] - 526s 108ms/step - loss: 45.9854 - val_loss: 47.7054\n",
            "Epoch 17/30\n",
            "4873/4873 [==============================] - 526s 108ms/step - loss: 45.9239 - val_loss: 47.9812\n",
            "Epoch 18/30\n",
            "4873/4873 [==============================] - 525s 108ms/step - loss: 45.0655 - val_loss: 52.5131\n",
            "Epoch 19/30\n",
            "4873/4873 [==============================] - 524s 108ms/step - loss: 45.8731 - val_loss: 46.2730\n",
            "Epoch 20/30\n",
            "4873/4873 [==============================] - 525s 108ms/step - loss: 44.7414 - val_loss: 45.8521\n",
            "Epoch 21/30\n",
            "4873/4873 [==============================] - 532s 109ms/step - loss: 43.7271 - val_loss: 45.8301\n",
            "Epoch 22/30\n",
            "4873/4873 [==============================] - 533s 109ms/step - loss: 43.5937 - val_loss: 45.3926\n",
            "Epoch 23/30\n",
            "4873/4873 [==============================] - 534s 110ms/step - loss: 42.9544 - val_loss: 45.2553\n",
            "Epoch 24/30\n",
            "4873/4873 [==============================] - 532s 109ms/step - loss: 42.5313 - val_loss: 45.1582\n",
            "Epoch 25/30\n",
            "3233/4873 [==================>...........] - ETA: 2:38 - loss: 42.1911"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model summary\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "uINBXb9Jk2lq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the best model saved during training\n",
        "model = load_model('/content/asr_best_model.keras', custom_objects={'ctc_lambda_func': ctc_lambda_func})\n",
        "\n",
        "# Print the model summary\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "uAF2Ph0gb7PS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the validation data\n",
        "val_loss = model.evaluate(val_gen, steps=validation_steps)\n",
        "print(f'Validation Loss: {val_loss}')"
      ],
      "metadata": {
        "id": "0oI2MuiYb-Y8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the model architecture\n",
        "plot_model(model, to_file='/content/model_architecture.png', show_shapes=True, show_layer_names=True)"
      ],
      "metadata": {
        "id": "IVXmW-oDcCoL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting the training history\n",
        "def plot_training_history(history):\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(history.history['loss'], label='Training Loss')\n",
        "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Training and Validation Loss Over Epochs')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "# Plot the training history\n",
        "plot_training_history(history)"
      ],
      "metadata": {
        "id": "G5hmrYr8UA4p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Redefine the inference model\n",
        "inference_model = Model(inputs=input_data, outputs=y_pred)\n",
        "\n",
        "# Load the weights from the best saved model\n",
        "inference_model.load_weights('/content/asr_best_model.keras')\n",
        "\n",
        "# Function to predict on a new sample\n",
        "def predict_sample(sample_index):\n",
        "    sample_features = X[sample_index]\n",
        "    sample_input_length = np.array([sample_features.shape[0]])\n",
        "\n",
        "    sample_features = np.expand_dims(sample_features, axis=0)\n",
        "    sample_input_length = np.array([sample_features.shape[1]], dtype=np.int32)\n",
        "\n",
        "    # Predict with beam search decoding\n",
        "    preds = inference_model.predict(sample_features)\n",
        "    decoded_pred = tf.keras.backend.ctc_decode(preds, input_length=sample_input_length, greedy=False, beam_width=20, top_paths=1)[0][0]\n",
        "    decoded_pred = tf.keras.backend.get_value(decoded_pred)\n",
        "\n",
        "    # Ensure decoded_pred is a 1D array\n",
        "    decoded_pred = decoded_pred.flatten()\n",
        "\n",
        "    # Convert the decoded prediction to text\n",
        "    predicted_text = ''.join([index_map[i] for i in decoded_pred if i != -1])\n",
        "\n",
        "    # Actual text from the dataset\n",
        "    actual_text = df.iloc[sample_index]['transcript']\n",
        "\n",
        "    print(f\"Predicted text: {predicted_text}\")\n",
        "    print(f\"Actual text: {actual_text}\")\n",
        "\n",
        "# Test the model on a new sample\n",
        "predict_sample(25)"
      ],
      "metadata": {
        "id": "AvJ4WpB5k1vu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}