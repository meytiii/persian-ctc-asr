{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jaa4L9zcFg0L",
        "outputId": "97d8993f-2f34-4be7-a567-b18b45458a86"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (611 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.8/611.8 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow-addons) (24.1)\n",
            "Collecting typeguard<3.0.0,>=2.7 (from tensorflow-addons)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Installing collected packages: typeguard, tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.23.0 typeguard-2.13.3\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow-addons"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TdDGgd3rGT7y",
        "outputId": "17bc761b-ff8a-4ea1-e1d3-3cdab8a75908"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
            "\n",
            "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
            "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
            "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
            "\n",
            "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
            "\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import librosa\n",
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, LSTM, Masking, Bidirectional, GRU, TimeDistributed, Dense, Activation, Lambda\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "id": "VPbcZY5AGV7N",
        "outputId": "7fecaae3-bd99-4e51-8d98-b743ade3418c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1jyvhdZHn0s5Owkr21k5Ff-c96sIQLtEu\n",
            "From (redirected): https://drive.google.com/uc?id=1jyvhdZHn0s5Owkr21k5Ff-c96sIQLtEu&confirm=t&uuid=9b2b6827-796d-4a0b-80c8-a6e1a1dad0b1\n",
            "To: /content/all_wav.zip\n",
            "100%|██████████| 2.48G/2.48G [01:09<00:00, 35.7MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1vqvn0F0YYhEFbzLgP9wJ36vyInUnO5b5\n",
            "To: /content/dataset.csv\n",
            "100%|██████████| 2.87M/2.87M [00:00<00:00, 134MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'dataset.csv'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# Download and unzip dataset\n",
        "import gdown\n",
        "\n",
        "url = 'https://drive.google.com/uc?id=1jyvhdZHn0s5Owkr21k5Ff-c96sIQLtEu'\n",
        "output = 'all_wav.zip'\n",
        "gdown.download(url, output, quiet=False)\n",
        "!unzip -q 'all_wav.zip' -d '/content/all_wav'\n",
        "\n",
        "url = 'https://drive.google.com/uc?id=1vqvn0F0YYhEFbzLgP9wJ36vyInUnO5b5'\n",
        "output = 'dataset.csv'\n",
        "gdown.download(url, output, quiet=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "id": "PjiQerrDHJCS",
        "outputId": "8700b68b-add1-4688-a4c8-82cd5511b676"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                           wav_filename  wav_filesize  \\\n",
              "0  ./all_wav/Tehran_SayeRoshan0_101.wav         83044   \n",
              "1  ./all_wav/Tehran_SayeRoshan0_105.wav         54468   \n",
              "2  ./all_wav/Tehran_SayeRoshan0_107.wav        136036   \n",
              "3  ./all_wav/Tehran_SayeRoshan0_108.wav        106788   \n",
              "4  ./all_wav/Tehran_SayeRoshan0_109.wav        170020   \n",
              "\n",
              "                                         transcript  confidence_level  \n",
              "0                            اتفاقاتی که ندیده بودم          0.927557  \n",
              "1                                              مسجد          0.927557  \n",
              "2                 جمع شدن مسلمین برای نمازهای جماعت          0.864152  \n",
              "3                          همیشه برای محمدرضا پهلوی          0.927557  \n",
              "4  چه زمانی در کسوت شاه ایران نوکری اجانب را می‌کرد          0.854824  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-621a59f5-b877-4848-ac99-0bb2d9f22568\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>wav_filename</th>\n",
              "      <th>wav_filesize</th>\n",
              "      <th>transcript</th>\n",
              "      <th>confidence_level</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>./all_wav/Tehran_SayeRoshan0_101.wav</td>\n",
              "      <td>83044</td>\n",
              "      <td>اتفاقاتی که ندیده بودم</td>\n",
              "      <td>0.927557</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>./all_wav/Tehran_SayeRoshan0_105.wav</td>\n",
              "      <td>54468</td>\n",
              "      <td>مسجد</td>\n",
              "      <td>0.927557</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>./all_wav/Tehran_SayeRoshan0_107.wav</td>\n",
              "      <td>136036</td>\n",
              "      <td>جمع شدن مسلمین برای نمازهای جماعت</td>\n",
              "      <td>0.864152</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>./all_wav/Tehran_SayeRoshan0_108.wav</td>\n",
              "      <td>106788</td>\n",
              "      <td>همیشه برای محمدرضا پهلوی</td>\n",
              "      <td>0.927557</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>./all_wav/Tehran_SayeRoshan0_109.wav</td>\n",
              "      <td>170020</td>\n",
              "      <td>چه زمانی در کسوت شاه ایران نوکری اجانب را می‌کرد</td>\n",
              "      <td>0.854824</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-621a59f5-b877-4848-ac99-0bb2d9f22568')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-621a59f5-b877-4848-ac99-0bb2d9f22568 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-621a59f5-b877-4848-ac99-0bb2d9f22568');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-32bd68d4-3f23-4c6d-bb38-95115aa1072c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-32bd68d4-3f23-4c6d-bb38-95115aa1072c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-32bd68d4-3f23-4c6d-bb38-95115aa1072c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 24366,\n  \"fields\": [\n    {\n      \"column\": \"wav_filename\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 24366,\n        \"samples\": [\n          \"./all_wav/Varzesh_ShabHayeNarenji44_72.wav\",\n          \"./all_wav/Varzesh_SakooyeMann10_183.wav\",\n          \"./all_wav/Tehran_YekTehranDoa0_241.wav\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"wav_filesize\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 78651,\n        \"min\": 50020,\n        \"max\": 399780,\n        \"num_unique_values\": 7819,\n        \"samples\": [\n          105700,\n          144580,\n          157316\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"transcript\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 21540,\n        \"samples\": [\n          \"\\u06cc\\u0639\\u0646\\u06cc \\u062e\\u0648\\u062f\\u062a \\u0645\\u06cc \\u0628\\u0631\\u06cc\\u0632 \\u062a\\u0648 \\u0645\\u06cc\\u0634\\u0648\\u0631\\u06cc\",\n          \"\\u062f\\u0631 \\u062c\\u0644\\u0633\\u0627\\u062a\",\n          \"\\u0647\\u062f\\u0641 \\u0647\\u0627\\u06cc \\u0645\\u0634\\u062e\\u0635 \\u0628\\u0647 \\u0622\\u0646\\u0647\\u0627 \\u062f\\u0627\\u062f\\u0647\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"confidence_level\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.04787249721394445,\n        \"min\": 0.79001349,\n        \"max\": 0.92755735,\n        \"num_unique_values\": 18100,\n        \"samples\": [\n          0.79745895,\n          0.83093834,\n          0.84155327\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "df = pd.read_csv('/content/dataset.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 786
        },
        "id": "S197rX3fFWos",
        "outputId": "d7deb996-17a6-4952-d02f-bf35f5cf2152"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "609/609 [==============================] - 106s 143ms/step - loss: 100.7496 - val_loss: 86.7232\n",
            "Epoch 2/10\n",
            "609/609 [==============================] - 80s 132ms/step - loss: 81.3988 - val_loss: 76.7036\n",
            "Epoch 3/10\n",
            "609/609 [==============================] - 80s 132ms/step - loss: 74.8681 - val_loss: 72.2083\n",
            "Epoch 4/10\n",
            "609/609 [==============================] - 81s 133ms/step - loss: 70.9910 - val_loss: 69.4241\n",
            "Epoch 5/10\n",
            "609/609 [==============================] - 80s 131ms/step - loss: 68.2764 - val_loss: 67.6312\n",
            "Epoch 6/10\n",
            "609/609 [==============================] - 80s 132ms/step - loss: 66.0165 - val_loss: 66.2682\n",
            "Epoch 7/10\n",
            "609/609 [==============================] - 81s 133ms/step - loss: 64.2835 - val_loss: 65.7788\n",
            "Epoch 8/10\n",
            "609/609 [==============================] - 82s 134ms/step - loss: 62.7256 - val_loss: 64.9456\n",
            "Epoch 9/10\n",
            "609/609 [==============================] - 83s 136ms/step - loss: 61.4526 - val_loss: 63.7964\n",
            "Epoch 10/10\n",
            "609/609 [==============================] - 80s 132ms/step - loss: 60.2362 - val_loss: 63.5106\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/saving/serialization_lib.py:403: UserWarning: The object being serialized includes a `lambda`. This is unsafe. In order to reload the object, you will have to pass `safe_mode=False` to the loading function. Please avoid using `lambda` in the future, and use named Python functions instead. This is the `lambda` being serialized: model.compile(optimizer=tf.keras.optimizers.Adam(), loss={'ctc': lambda y_true, y_pred: y_pred})\n",
            "\n",
            "  return {key: serialize_keras_object(value) for key, value in obj.items()}\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "You called `set_weights(weights)` on layer \"model_1\" with a weight list of length 12, but the layer was expecting 14 weights. Provided weights: [array([[-0.1562423 ,  0.04193013, -0.05970337, .....",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-7f262aa2301c>\u001b[0m in \u001b[0;36m<cell line: 148>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;31m# Define inference model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0minference_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m \u001b[0minference_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;31m# Load a sample and predict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/base_layer.py\u001b[0m in \u001b[0;36mset_weights\u001b[0;34m(self, weights)\u001b[0m\n\u001b[1;32m   1795\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1796\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mexpected_num_weights\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1797\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m   1798\u001b[0m                 \u001b[0;34m'You called `set_weights(weights)` on layer \"%s\" '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1799\u001b[0m                 \u001b[0;34m\"with a weight list of length %s, but the layer was \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: You called `set_weights(weights)` on layer \"model_1\" with a weight list of length 12, but the layer was expecting 14 weights. Provided weights: [array([[-0.1562423 ,  0.04193013, -0.05970337, ....."
          ]
        }
      ],
      "source": [
        "# Load dataset\n",
        "df = pd.read_csv('/content/dataset.csv')\n",
        "\n",
        "# Update paths for WAV files\n",
        "df['wav_filename'] = df['wav_filename'].apply(lambda x: x.replace('./all_wav/', '/content/all_wav/all_wav/'))\n",
        "\n",
        "# Filter dataset to include only existing WAV files\n",
        "df = df[df['wav_filename'].apply(os.path.isfile)]\n",
        "\n",
        "# Character map for Persian characters\n",
        "char_map_str = \"\"\"\n",
        "' 0\n",
        "<SPACE> 1\n",
        "ا 2\n",
        "ب 3\n",
        "پ 4\n",
        "ت 5\n",
        "ث 6\n",
        "ج 7\n",
        "چ 8\n",
        "ح 9\n",
        "خ 10\n",
        "د 11\n",
        "ذ 12\n",
        "ر 13\n",
        "ز 14\n",
        "ژ 15\n",
        "س 16\n",
        "ش 17\n",
        "ص 18\n",
        "ض 19\n",
        "ط 20\n",
        "ظ 21\n",
        "ع 22\n",
        "غ 23\n",
        "ف 24\n",
        "ق 25\n",
        "ک 26\n",
        "گ 27\n",
        "ل 28\n",
        "م 29\n",
        "ن 30\n",
        "و 31\n",
        "ه 32\n",
        "ی 33\n",
        "، 34\n",
        "؟ 35\n",
        "\"\"\"\n",
        "char_map = {}\n",
        "index_map = {}\n",
        "for line in char_map_str.strip().split('\\n'):\n",
        "    ch, index = line.split()\n",
        "    char_map[ch] = int(index)\n",
        "    index_map[int(index)] = ch\n",
        "index_map[1] = ' '\n",
        "\n",
        "# Ensure space character is in char_map\n",
        "char_map[' '] = char_map['<SPACE>']\n",
        "\n",
        "# Audio processing functions\n",
        "def load_audio(file_path, sr=16000):\n",
        "    audio, _ = librosa.load(file_path, sr=sr)\n",
        "    return audio\n",
        "\n",
        "def extract_features(audio, n_mfcc=13, sr=16000):\n",
        "    mfcc_features = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=n_mfcc)\n",
        "    return mfcc_features.T\n",
        "\n",
        "# Prepare the dataset\n",
        "X = []\n",
        "y = []\n",
        "input_lengths = []\n",
        "label_lengths = []\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "    audio_path = row['wav_filename']\n",
        "    audio = load_audio(audio_path)\n",
        "    features = extract_features(audio)\n",
        "    X.append(features)\n",
        "    input_lengths.append([features.shape[0]])\n",
        "    label = [char_map.get(c, char_map[' ']) for c in row['transcript']]\n",
        "    y.append(label)\n",
        "    label_lengths.append([len(label)])\n",
        "\n",
        "if len(X) == 0 or len(y) == 0:\n",
        "    raise ValueError(\"No valid audio files were found. Please check the dataset and the paths.\")\n",
        "\n",
        "X = tf.keras.preprocessing.sequence.pad_sequences(X, padding='post', dtype='float32')\n",
        "y = tf.keras.preprocessing.sequence.pad_sequences(y, padding='post', value=-1)\n",
        "\n",
        "# Define the model\n",
        "input_data = Input(name='the_input', shape=(None, 13))\n",
        "masking_layer = Masking(mask_value=0.0)(input_data)\n",
        "bilstm_layer_1 = Bidirectional(LSTM(128, return_sequences=True))(masking_layer)\n",
        "bilstm_layer_2 = Bidirectional(LSTM(128, return_sequences=True))(bilstm_layer_1)\n",
        "time_dense = TimeDistributed(Dense(len(char_map) + 1))(bilstm_layer_2)\n",
        "y_pred = Activation('softmax', name='activation')(time_dense)\n",
        "\n",
        "# Define the CTC loss function\n",
        "def ctc_lambda_func(args):\n",
        "    y_pred, labels, input_length, label_length = args\n",
        "    return K.ctc_batch_cost(labels, y_pred, input_length, label_length)\n",
        "\n",
        "# Compile the model with CTC loss\n",
        "labels = Input(name='the_labels', shape=[None], dtype='float32')\n",
        "input_length = Input(name='input_length', shape=[1], dtype='int64')\n",
        "label_length = Input(name='label_length', shape=[1], dtype='int64')\n",
        "loss_out = Lambda(ctc_lambda_func, output_shape=(1,), name='ctc')([y_pred, labels, input_length, label_length])\n",
        "\n",
        "model = Model(inputs=[input_data, labels, input_length, label_length], outputs=loss_out)\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(), loss={'ctc': lambda y_true, y_pred: y_pred})\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "X_train, X_val, y_train, y_val, input_length_train, input_length_val, label_length_train, label_length_val = train_test_split(X, y, input_lengths, label_lengths, test_size=0.2, random_state=42)\n",
        "\n",
        "# Data generator\n",
        "def data_generator(X, y, input_lengths, label_lengths, batch_size=32):\n",
        "    while True:\n",
        "        for i in range(0, len(X), batch_size):\n",
        "            X_batch = X[i:i+batch_size]\n",
        "            y_batch = y[i:i+batch_size]\n",
        "            input_lengths_batch = input_lengths[i:i+batch_size]\n",
        "            label_lengths_batch = label_lengths[i:i+batch_size]\n",
        "            yield (\n",
        "                {\n",
        "                    'the_input': np.array(X_batch),\n",
        "                    'the_labels': np.array(y_batch),\n",
        "                    'input_length': np.array(input_lengths_batch),\n",
        "                    'label_length': np.array(label_lengths_batch)\n",
        "                },\n",
        "                np.zeros(len(X_batch))\n",
        "            )\n",
        "\n",
        "train_gen = data_generator(X_train, y_train, input_length_train, label_length_train, batch_size=32)\n",
        "val_gen = data_generator(X_val, y_val, input_length_val, label_length_val, batch_size=32)\n",
        "\n",
        "steps_per_epoch = len(X_train) // 32\n",
        "validation_steps = len(X_val) // 32\n",
        "\n",
        "# Train the model\n",
        "model.fit(train_gen, steps_per_epoch=steps_per_epoch, epochs=10, validation_data=val_gen, validation_steps=validation_steps)\n",
        "\n",
        "# Save the model\n",
        "model.save('asr_model.keras')\n",
        "\n",
        "# Define inference model\n",
        "inference_model = Model(inputs=input_data, outputs=y_pred)\n",
        "inference_model.set_weights(model.get_weights()[:-2])\n",
        "\n",
        "# Load a sample and predict\n",
        "sample_index = 0\n",
        "sample_features = X[sample_index]\n",
        "sample_input_length = np.array([input_length_train[sample_index]])\n",
        "\n",
        "sample_features = np.expand_dims(sample_features, axis=0)\n",
        "sample_input_length = np.expand_dims(sample_input_length, axis=0)\n",
        "\n",
        "preds = inference_model.predict(sample_features)\n",
        "decoded_pred = tf.keras.backend.ctc_decode(preds, input_length=sample_input_length)[0][0]\n",
        "decoded_pred = tf.keras.backend.get_value(decoded_pred)\n",
        "\n",
        "predicted_text = ''.join([index_map[i] for i in decoded_pred if i != -1])\n",
        "\n",
        "actual_text = df.iloc[sample_index]['transcript']\n",
        "\n",
        "print(f\"Predicted text: {predicted_text}\")\n",
        "print(f\"Actual text: {actual_text}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}