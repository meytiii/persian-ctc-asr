{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Importing Necessary Libraries**"
      ],
      "metadata": {
        "id": "AzwiYqVpF4nq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "NG2dctbq6CzW"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import librosa\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, LSTM, Dense, Masking, TimeDistributed, Activation, Bidirectional, Lambda, Dropout, BatchNormalization\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Downloading and Unzipping Dataset**"
      ],
      "metadata": {
        "id": "UaY3hchVF7gn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code downloads and unzips the audio files and the dataset CSV file from Google Drive."
      ],
      "metadata": {
        "id": "rkRG9u2KHAHA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown\n",
        "\n",
        "url = 'https://drive.google.com/uc?id=1jyvhdZHn0s5Owkr21k5Ff-c96sIQLtEu'\n",
        "output = 'all_wav.zip'\n",
        "gdown.download(url, output, quiet=False)\n",
        "!unzip -q 'all_wav.zip' -d '/content/all_wav'\n",
        "\n",
        "url = 'https://drive.google.com/uc?id=1vqvn0F0YYhEFbzLgP9wJ36vyInUnO5b5'\n",
        "output = 'dataset.csv'\n",
        "gdown.download(url, output, quiet=False)"
      ],
      "metadata": {
        "id": "40-VxSiT6r5i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loading the Dataset CSV File**"
      ],
      "metadata": {
        "id": "JPtO4-0RHDTm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code loads the dataset CSV file, updates the paths to the audio files, and filters out any non-existent audio files."
      ],
      "metadata": {
        "id": "PI6UaN3MHFNr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "df = pd.read_csv('/content/dataset.csv')\n",
        "df.head()\n",
        "\n",
        "# Update paths for WAV files\n",
        "df['wav_filename'] = df['wav_filename'].apply(lambda x: x.replace('./all_wav/', '/content/all_wav/all_wav/'))\n",
        "\n",
        "# Filter dataset to include only existing WAV files\n",
        "df = df[df['wav_filename'].apply(os.path.isfile)]"
      ],
      "metadata": {
        "id": "7WZDKxHG6zxX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creating Character Maps**"
      ],
      "metadata": {
        "id": "HhWiSahuHWkX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code creates mappings between Persian characters and their corresponding indices for use in the model."
      ],
      "metadata": {
        "id": "f55-EhBVHaZn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Character map for Persian characters\n",
        "char_map_str = \"\"\"\n",
        "' 0\n",
        "<SPACE> 1\n",
        "ا 2\n",
        "ب 3\n",
        "پ 4\n",
        "ت 5\n",
        "ث 6\n",
        "ج 7\n",
        "چ 8\n",
        "ح 9\n",
        "خ 10\n",
        "د 11\n",
        "ذ 12\n",
        "ر 13\n",
        "ز 14\n",
        "ژ 15\n",
        "س 16\n",
        "ش 17\n",
        "ص 18\n",
        "ض 19\n",
        "ط 20\n",
        "ظ 21\n",
        "ع 22\n",
        "غ 23\n",
        "ف 24\n",
        "ق 25\n",
        "ک 26\n",
        "گ 27\n",
        "ل 28\n",
        "م 29\n",
        "ن 30\n",
        "و 31\n",
        "ه 32\n",
        "ی 33\n",
        "، 34\n",
        "؟ 35\n",
        "\"\"\"\n",
        "char_map = {}\n",
        "index_map = {}\n",
        "for line in char_map_str.strip().split('\\n'):\n",
        "    ch, index = line.split()\n",
        "    char_map[ch] = int(index)\n",
        "    index_map[int(index)] = ch\n",
        "index_map[1] = ' '\n",
        "\n",
        "# Ensure space character is in char_map\n",
        "char_map[' '] = char_map['<SPACE>']"
      ],
      "metadata": {
        "id": "yd532EM9HYJO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Defining Audio Processing Functions**"
      ],
      "metadata": {
        "id": "0hRNa_21Hczu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code defines functions for loading audio, extracting features, adding noise, and shifting time to augment the dataset."
      ],
      "metadata": {
        "id": "RSk26uNXHkTC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Audio processing functions\n",
        "def load_audio(file_path, sr=16000):\n",
        "    audio, _ = librosa.load(file_path, sr=sr)\n",
        "    return audio\n",
        "\n",
        "def extract_features(audio, n_mfcc=20, sr=16000):\n",
        "    mfcc_features = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=n_mfcc)\n",
        "    delta_mfcc = librosa.feature.delta(mfcc_features)\n",
        "    combined = np.vstack((mfcc_features, delta_mfcc)).T\n",
        "    return combined\n",
        "\n",
        "def add_noise(audio, noise_factor=0.005):\n",
        "    noise = np.random.randn(len(audio))\n",
        "    augmented_audio = audio + noise_factor * noise\n",
        "    augmented_audio = augmented_audio.astype(type(audio[0]))\n",
        "    return augmented_audio\n",
        "\n",
        "def shift_time(audio, shift_max=0.2):\n",
        "    shift = np.random.randint(int(shift_max * 16000))\n",
        "    if np.random.rand() > 0.5:\n",
        "        shift = -shift\n",
        "    augmented_audio = np.roll(audio, shift)\n",
        "    if shift > 0:\n",
        "        augmented_audio[:shift] = 0\n",
        "    else:\n",
        "        augmented_audio[shift:] = 0\n",
        "    return augmented_audio"
      ],
      "metadata": {
        "id": "s5H_51cbHheU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Preparing the Dataset**"
      ],
      "metadata": {
        "id": "vHufP8djHmA_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code processes the audio files, extracts features, and prepares the input and output sequences for the model."
      ],
      "metadata": {
        "id": "ti0IFS03HmlU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare the dataset\n",
        "X = []\n",
        "y = []\n",
        "input_lengths = []\n",
        "label_lengths = []\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "    audio_path = row['wav_filename']\n",
        "    audio = load_audio(audio_path)\n",
        "    audio = add_noise(audio)\n",
        "    audio = shift_time(audio)\n",
        "    features = extract_features(audio)\n",
        "    X.append(features)\n",
        "    input_lengths.append(features.shape[0])\n",
        "    label = [char_map.get(c, char_map[' ']) for c in row['transcript']]\n",
        "    y.append(label)\n",
        "    label_lengths.append(len(label))\n",
        "\n",
        "if len(X) == 0 or len(y) == 0:\n",
        "    raise ValueError(\"No valid audio files were found. Please check the dataset and the paths.\")\n",
        "\n",
        "X = tf.keras.preprocessing.sequence.pad_sequences(X, padding='post', dtype='float32')\n",
        "y = tf.keras.preprocessing.sequence.pad_sequences(y, padding='post', value=-1)"
      ],
      "metadata": {
        "id": "tMb93EdCHm06"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Defining the Model**"
      ],
      "metadata": {
        "id": "iB_5MTJ9HsqA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code defines the architecture of the deep learning model using Bidirectional LSTMs, Batch Normalization, and TimeDistributed Dense layers."
      ],
      "metadata": {
        "id": "sH53onBFHs18"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model with increased LSTM units to 256\n",
        "input_data = Input(name='the_input', shape=(None, 40))\n",
        "masking_layer = Masking(mask_value=0.0)(input_data)\n",
        "bilstm_layer_1 = Bidirectional(LSTM(256, return_sequences=True))(masking_layer)\n",
        "batch_norm_1 = BatchNormalization()(bilstm_layer_1)\n",
        "bilstm_layer_2 = Bidirectional(LSTM(256, return_sequences=True))(batch_norm_1)\n",
        "batch_norm_2 = BatchNormalization()(bilstm_layer_2)\n",
        "time_dense = TimeDistributed(Dense(len(char_map) + 1))(batch_norm_2)\n",
        "y_pred = Activation('softmax', name='activation')(time_dense)"
      ],
      "metadata": {
        "id": "tH3Be6reHwac"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Defining CTC Loss and Compiling the Model**"
      ],
      "metadata": {
        "id": "HG3C-gL1HzCt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code defines the CTC loss function and compiles the model with it."
      ],
      "metadata": {
        "id": "aVMkh_pOH0pM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the CTC loss function\n",
        "def ctc_lambda_func(args):\n",
        "    y_pred, labels, input_length, label_length = args\n",
        "    return tf.keras.backend.ctc_batch_cost(labels, y_pred, input_length, label_length)\n",
        "\n",
        "# Compile the model with CTC loss\n",
        "labels = Input(name='the_labels', shape=[None], dtype='float32')\n",
        "input_length = Input(name='input_length', shape=[1], dtype='int64')\n",
        "label_length = Input(name='label_length', shape=[1], dtype='int64')\n",
        "loss_out = Lambda(ctc_lambda_func, output_shape=(1,), name='ctc')([y_pred, labels, input_length, label_length])\n",
        "\n",
        "model = Model(inputs=[input_data, labels, input_length, label_length], outputs=loss_out)\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss={'ctc': ctc_lambda_func})"
      ],
      "metadata": {
        "id": "tx4QsuMVH1ID"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Splitting Data and Defining Data Generator**"
      ],
      "metadata": {
        "id": "xeU2wc7FH3UP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code splits the dataset into training and validation sets and defines a data generator for batch processing."
      ],
      "metadata": {
        "id": "u_UpL16DH4qP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and validation sets\n",
        "X_train, X_val, y_train, y_val, input_length_train, input_length_val, label_length_train, label_length_val = train_test_split(X, y, input_lengths, label_lengths, test_size=0.2, random_state=42)\n",
        "\n",
        "def data_generator(X, y, input_lengths, label_lengths, batch_size=16):\n",
        "    while True:\n",
        "        for i in range(0, len(X), batch_size):\n",
        "            X_batch = X[i:i+batch_size]\n",
        "            y_batch = y[i:i+batch_size]\n",
        "            input_lengths_batch = input_lengths[i:i+batch_size]\n",
        "            label_lengths_batch = label_lengths[i:i+batch_size]\n",
        "            yield (\n",
        "                {\n",
        "                    'the_input': np.array(X_batch),\n",
        "                    'the_labels': np.array(y_batch),\n",
        "                    'input_length': np.array(input_lengths_batch),\n",
        "                    'label_length': np.array(label_lengths_batch)\n",
        "                },\n",
        "                {'ctc': np.zeros([len(X_batch)])}\n",
        "            )\n",
        "\n",
        "train_gen = data_generator(X_train, y_train, input_length_train, label_length_train, batch_size=16)\n",
        "val_gen = data_generator(X_val, y_val, input_length_val, label_length_val, batch_size=16)"
      ],
      "metadata": {
        "id": "IyNaDeebH5DP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Defining Callbacks and Training the Model**"
      ],
      "metadata": {
        "id": "ac3Kb8xzH7Mr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code defines the callbacks for early stopping and model checkpointing, and trains the model."
      ],
      "metadata": {
        "id": "c8GnWGilH8nF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define callbacks\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "model_checkpoint = ModelCheckpoint('/content/asr_best_model.keras', monitor='val_loss', save_best_only=True)\n",
        "\n",
        "# Train the model\n",
        "model.fit(train_gen, steps_per_epoch=len(X_train) // 16, epochs=30, validation_data=val_gen, validation_steps=len(X_val) // 16, callbacks=[early_stopping, model_checkpoint])"
      ],
      "metadata": {
        "id": "4kEwLWlEH89v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Saving the Model and Displaying Summary**"
      ],
      "metadata": {
        "id": "hh-rzK2QICgH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the final model\n",
        "model.save('/content/asr_model.keras')\n",
        "\n",
        "# Model summary\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "cErG75d5IFeV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Redefining Inference Model and Loading Weights**"
      ],
      "metadata": {
        "id": "sx00nNGrIHHp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code redefines the inference model and loads the best model weights."
      ],
      "metadata": {
        "id": "ITEPJXF1II6w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Redefine the inference model\n",
        "inference_model = Model(inputs=input_data, outputs=y_pred)\n",
        "\n",
        "# Load the weights from the best saved model\n",
        "inference_model.load_weights('/content/asr_best_model.keras')"
      ],
      "metadata": {
        "id": "tMCNImT4IIcU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Predicting on a New Sample**"
      ],
      "metadata": {
        "id": "Nu_C2SHTILMU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code defines a function to predict on a new sample and tests the model on a specific sample index. Adjust the sample_index to test on different samples."
      ],
      "metadata": {
        "id": "nUQLPhabIPyi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to predict on a new sample\n",
        "def predict_sample(sample_index):\n",
        "    sample_features = X[sample_index]\n",
        "    sample_input_length = np.array([sample_features.shape[0]])\n",
        "\n",
        "    sample_features = np.expand_dims(sample_features, axis=0)\n",
        "    sample_input_length = np.array([sample_features.shape[1]], dtype=np.int32)\n",
        "\n",
        "    # Predict with beam search decoding\n",
        "    preds = inference_model.predict(sample_features)\n",
        "    decoded_pred = tf.keras.backend.ctc_decode(preds, input_length=sample_input_length, greedy=False, beam_width=10, top_paths=1)[0][0]\n",
        "    decoded_pred = tf.keras.backend.get_value(decoded_pred)\n",
        "\n",
        "    # Ensure decoded_pred is a 1D array\n",
        "    decoded_pred = decoded_pred.flatten()\n",
        "\n",
        "    # Convert the decoded prediction to text\n",
        "    predicted_text = ''.join([index_map[i] for i in decoded_pred if i != -1])\n",
        "\n",
        "    # Actual text from the dataset\n",
        "    actual_text = df.iloc[sample_index]['transcript']\n",
        "\n",
        "    print(f\"Predicted text: {predicted_text}\")\n",
        "    print(f\"Actual text: {actual_text}\")\n",
        "\n",
        "# Test the model on a new sample\n",
        "predict_sample(25)"
      ],
      "metadata": {
        "id": "F-IRUBToIN8-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}