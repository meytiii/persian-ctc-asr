{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Persian ASR using CTC Loss function**"
      ],
      "metadata": {
        "id": "V5MFT51OJw4D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Importing Necessary Libraries**"
      ],
      "metadata": {
        "id": "AzwiYqVpF4nq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "NG2dctbq6CzW"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import librosa\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, LSTM, Dense, Masking, TimeDistributed, Activation, Bidirectional, Lambda, Dropout, BatchNormalization\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Downloading and Unzipping Dataset**"
      ],
      "metadata": {
        "id": "UaY3hchVF7gn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code downloads and unzips the audio files and the dataset CSV file from Google Drive.\n",
        "The dataset is made by Hamtech (https://ham-tech.ir/)"
      ],
      "metadata": {
        "id": "rkRG9u2KHAHA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown\n",
        "\n",
        "url = 'https://drive.google.com/uc?id=1jyvhdZHn0s5Owkr21k5Ff-c96sIQLtEu'\n",
        "output = 'all_wav.zip'\n",
        "gdown.download(url, output, quiet=False)\n",
        "!unzip -q 'all_wav.zip' -d '/content/all_wav'\n",
        "\n",
        "url = 'https://drive.google.com/uc?id=1vqvn0F0YYhEFbzLgP9wJ36vyInUnO5b5'\n",
        "output = 'dataset.csv'\n",
        "gdown.download(url, output, quiet=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192
        },
        "id": "40-VxSiT6r5i",
        "outputId": "69248501-0b7e-48b7-ffb3-1bf44f00adb8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1jyvhdZHn0s5Owkr21k5Ff-c96sIQLtEu\n",
            "From (redirected): https://drive.google.com/uc?id=1jyvhdZHn0s5Owkr21k5Ff-c96sIQLtEu&confirm=t&uuid=604ee740-bd88-46e4-b72b-63dad2710b03\n",
            "To: /content/all_wav.zip\n",
            "100%|██████████| 2.48G/2.48G [00:10<00:00, 228MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1vqvn0F0YYhEFbzLgP9wJ36vyInUnO5b5\n",
            "To: /content/dataset.csv\n",
            "100%|██████████| 2.87M/2.87M [00:00<00:00, 220MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'dataset.csv'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loading the Dataset CSV File**"
      ],
      "metadata": {
        "id": "JPtO4-0RHDTm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code loads the dataset CSV file, displays the first few rows, updates the paths to the audio files, and filters out any non-existent audio files. Since more than 9GB of .wav files are lost but they are still existing in our dataset.csv"
      ],
      "metadata": {
        "id": "PI6UaN3MHFNr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "df = pd.read_csv('/content/dataset.csv')\n",
        "df.head()\n",
        "\n",
        "# Update paths for WAV files\n",
        "df['wav_filename'] = df['wav_filename'].apply(lambda x: x.replace('./all_wav/', '/content/all_wav/all_wav/'))\n",
        "\n",
        "# Filter dataset to include only existing WAV files\n",
        "df = df[df['wav_filename'].apply(os.path.isfile)]"
      ],
      "metadata": {
        "id": "7WZDKxHG6zxX"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "bTTIa_iuLPlx",
        "outputId": "629995e4-7272-469f-a447-148f283afc60"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                        wav_filename  wav_filesize  \\\n",
              "0  /content/all_wav/all_wav/Tehran_SayeRoshan0_10...         83044   \n",
              "1  /content/all_wav/all_wav/Tehran_SayeRoshan0_10...         54468   \n",
              "2  /content/all_wav/all_wav/Tehran_SayeRoshan0_10...        136036   \n",
              "3  /content/all_wav/all_wav/Tehran_SayeRoshan0_10...        106788   \n",
              "4  /content/all_wav/all_wav/Tehran_SayeRoshan0_10...        170020   \n",
              "\n",
              "                                         transcript  confidence_level  \n",
              "0                            اتفاقاتی که ندیده بودم          0.927557  \n",
              "1                                              مسجد          0.927557  \n",
              "2                 جمع شدن مسلمین برای نمازهای جماعت          0.864152  \n",
              "3                          همیشه برای محمدرضا پهلوی          0.927557  \n",
              "4  چه زمانی در کسوت شاه ایران نوکری اجانب را می‌کرد          0.854824  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a636c58b-530a-4bce-ad70-b4db878b8137\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>wav_filename</th>\n",
              "      <th>wav_filesize</th>\n",
              "      <th>transcript</th>\n",
              "      <th>confidence_level</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>/content/all_wav/all_wav/Tehran_SayeRoshan0_10...</td>\n",
              "      <td>83044</td>\n",
              "      <td>اتفاقاتی که ندیده بودم</td>\n",
              "      <td>0.927557</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/content/all_wav/all_wav/Tehran_SayeRoshan0_10...</td>\n",
              "      <td>54468</td>\n",
              "      <td>مسجد</td>\n",
              "      <td>0.927557</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>/content/all_wav/all_wav/Tehran_SayeRoshan0_10...</td>\n",
              "      <td>136036</td>\n",
              "      <td>جمع شدن مسلمین برای نمازهای جماعت</td>\n",
              "      <td>0.864152</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>/content/all_wav/all_wav/Tehran_SayeRoshan0_10...</td>\n",
              "      <td>106788</td>\n",
              "      <td>همیشه برای محمدرضا پهلوی</td>\n",
              "      <td>0.927557</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>/content/all_wav/all_wav/Tehran_SayeRoshan0_10...</td>\n",
              "      <td>170020</td>\n",
              "      <td>چه زمانی در کسوت شاه ایران نوکری اجانب را می‌کرد</td>\n",
              "      <td>0.854824</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a636c58b-530a-4bce-ad70-b4db878b8137')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a636c58b-530a-4bce-ad70-b4db878b8137 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a636c58b-530a-4bce-ad70-b4db878b8137');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-1290c263-4d9a-4675-a8ff-e2fbd1016159\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1290c263-4d9a-4675-a8ff-e2fbd1016159')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-1290c263-4d9a-4675-a8ff-e2fbd1016159 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 24366,\n  \"fields\": [\n    {\n      \"column\": \"wav_filename\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 24366,\n        \"samples\": [\n          \"/content/all_wav/all_wav/Varzesh_ShabHayeNarenji44_72.wav\",\n          \"/content/all_wav/all_wav/Varzesh_SakooyeMann10_183.wav\",\n          \"/content/all_wav/all_wav/Tehran_YekTehranDoa0_241.wav\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"wav_filesize\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 78651,\n        \"min\": 50020,\n        \"max\": 399780,\n        \"num_unique_values\": 7819,\n        \"samples\": [\n          105700,\n          144580,\n          157316\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"transcript\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 21540,\n        \"samples\": [\n          \"\\u06cc\\u0639\\u0646\\u06cc \\u062e\\u0648\\u062f\\u062a \\u0645\\u06cc \\u0628\\u0631\\u06cc\\u0632 \\u062a\\u0648 \\u0645\\u06cc\\u0634\\u0648\\u0631\\u06cc\",\n          \"\\u062f\\u0631 \\u062c\\u0644\\u0633\\u0627\\u062a\",\n          \"\\u0647\\u062f\\u0641 \\u0647\\u0627\\u06cc \\u0645\\u0634\\u062e\\u0635 \\u0628\\u0647 \\u0622\\u0646\\u0647\\u0627 \\u062f\\u0627\\u062f\\u0647\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"confidence_level\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.04787249721394445,\n        \"min\": 0.79001349,\n        \"max\": 0.92755735,\n        \"num_unique_values\": 18100,\n        \"samples\": [\n          0.79745895,\n          0.83093834,\n          0.84155327\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creating Character Maps**"
      ],
      "metadata": {
        "id": "HhWiSahuHWkX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create mappings between Persian characters and their corresponding indices for use in the model. These mappings are used to convert text to a sequence of indices and vice versa."
      ],
      "metadata": {
        "id": "f55-EhBVHaZn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Character map for Persian characters\n",
        "char_map_str = \"\"\"\n",
        "' 0\n",
        "<SPACE> 1\n",
        "ا 2\n",
        "ب 3\n",
        "پ 4\n",
        "ت 5\n",
        "ث 6\n",
        "ج 7\n",
        "چ 8\n",
        "ح 9\n",
        "خ 10\n",
        "د 11\n",
        "ذ 12\n",
        "ر 13\n",
        "ز 14\n",
        "ژ 15\n",
        "س 16\n",
        "ش 17\n",
        "ص 18\n",
        "ض 19\n",
        "ط 20\n",
        "ظ 21\n",
        "ع 22\n",
        "غ 23\n",
        "ف 24\n",
        "ق 25\n",
        "ک 26\n",
        "گ 27\n",
        "ل 28\n",
        "م 29\n",
        "ن 30\n",
        "و 31\n",
        "ه 32\n",
        "ی 33\n",
        "، 34\n",
        "؟ 35\n",
        "\"\"\"\n",
        "char_map = {}\n",
        "index_map = {}\n",
        "for line in char_map_str.strip().split('\\n'):\n",
        "    ch, index = line.split()\n",
        "    char_map[ch] = int(index)\n",
        "    index_map[int(index)] = ch\n",
        "index_map[1] = ' '\n",
        "\n",
        "# Ensure space character is in char_map\n",
        "char_map[' '] = char_map['<SPACE>']"
      ],
      "metadata": {
        "id": "yd532EM9HYJO"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Defining Audio Processing Functions**"
      ],
      "metadata": {
        "id": "0hRNa_21Hczu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define functions for loading audio, extracting features, adding noise, and shifting time to augment the dataset. These augmentations help make the model more robust to variations in the audio data."
      ],
      "metadata": {
        "id": "RSk26uNXHkTC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Audio processing functions\n",
        "def load_audio(file_path, sr=16000):\n",
        "    audio, _ = librosa.load(file_path, sr=sr)\n",
        "    return audio\n",
        "\n",
        "def extract_features(audio, n_mfcc=20, sr=16000):\n",
        "    mfcc_features = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=n_mfcc)\n",
        "    delta_mfcc = librosa.feature.delta(mfcc_features)\n",
        "    combined = np.vstack((mfcc_features, delta_mfcc)).T\n",
        "    return combined\n",
        "\n",
        "def add_noise(audio, noise_factor=0.005):\n",
        "    noise = np.random.randn(len(audio))\n",
        "    augmented_audio = audio + noise_factor * noise\n",
        "    augmented_audio = augmented_audio.astype(type(audio[0]))\n",
        "    return augmented_audio\n",
        "\n",
        "def shift_time(audio, shift_max=0.2):\n",
        "    shift = np.random.randint(int(shift_max * 16000))\n",
        "    if np.random.rand() > 0.5:\n",
        "        shift = -shift\n",
        "    augmented_audio = np.roll(audio, shift)\n",
        "    if shift > 0:\n",
        "        augmented_audio[:shift] = 0\n",
        "    else:\n",
        "        augmented_audio[shift:] = 0\n",
        "    return augmented_audio"
      ],
      "metadata": {
        "id": "s5H_51cbHheU"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Preparing the Dataset**"
      ],
      "metadata": {
        "id": "vHufP8djHmA_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Processe the audio files, extract features, and prepare the input and output sequences for the model. The audio features are padded to ensure uniform input length for the model, and the text labels are converted to sequences of indices."
      ],
      "metadata": {
        "id": "ti0IFS03HmlU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare the dataset\n",
        "X = []\n",
        "y = []\n",
        "input_lengths = []\n",
        "label_lengths = []\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "    audio_path = row['wav_filename']\n",
        "    audio = load_audio(audio_path)\n",
        "    audio = add_noise(audio)\n",
        "    audio = shift_time(audio)\n",
        "    features = extract_features(audio)\n",
        "    X.append(features)\n",
        "    input_lengths.append(features.shape[0])\n",
        "    label = [char_map.get(c, char_map[' ']) for c in row['transcript']]\n",
        "    y.append(label)\n",
        "    label_lengths.append(len(label))\n",
        "\n",
        "if len(X) == 0 or len(y) == 0:\n",
        "    raise ValueError(\"No valid audio files were found. Please check the dataset and the paths.\")\n",
        "\n",
        "X = tf.keras.preprocessing.sequence.pad_sequences(X, padding='post', dtype='float32')\n",
        "y = tf.keras.preprocessing.sequence.pad_sequences(y, padding='post', value=-1)"
      ],
      "metadata": {
        "id": "tMb93EdCHm06"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Defining the Model**\n",
        "\n",
        "*   **Input**: Defines the input layer with shape (None, 40), where None indicates variable sequence length and 40 is the number of features.\n",
        "\n",
        "*   **Masking**: Masks the padded values (0.0) in the input sequences.\n",
        "\n",
        "*   **Bidirectional LSTM**: Two Bidirectional LSTM layers with 256 units each are used to capture temporal dependencies in both forward and backward directions.\n",
        "\n",
        "*   **BatchNormalization**: Normalizes the activations of the LSTM layers to improve training stability and performance.\n",
        "\n",
        "*   **TimeDistributed Dense**: Applies a dense layer to each time step of the sequence independently.\n",
        "\n",
        "*   **Activation**: Applies a softmax activation to generate a probability distribution over the output characters for each time step.\n",
        "\n"
      ],
      "metadata": {
        "id": "iB_5MTJ9HsqA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model with increased LSTM units to 256\n",
        "input_data = Input(name='the_input', shape=(None, 40))\n",
        "masking_layer = Masking(mask_value=0.0)(input_data)\n",
        "bilstm_layer_1 = Bidirectional(LSTM(256, return_sequences=True))(masking_layer)\n",
        "batch_norm_1 = BatchNormalization()(bilstm_layer_1)\n",
        "bilstm_layer_2 = Bidirectional(LSTM(256, return_sequences=True))(batch_norm_1)\n",
        "batch_norm_2 = BatchNormalization()(bilstm_layer_2)\n",
        "time_dense = TimeDistributed(Dense(len(char_map) + 1))(batch_norm_2)\n",
        "y_pred = Activation('softmax', name='activation')(time_dense)"
      ],
      "metadata": {
        "id": "tH3Be6reHwac"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Defining CTC Loss and Compiling the Model**"
      ],
      "metadata": {
        "id": "HG3C-gL1HzCt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code defines the CTC loss function and compiles the model with it."
      ],
      "metadata": {
        "id": "aVMkh_pOH0pM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the CTC loss function\n",
        "def ctc_lambda_func(args):\n",
        "    y_pred, labels, input_length, label_length = args\n",
        "    return tf.keras.backend.ctc_batch_cost(labels, y_pred, input_length, label_length)\n",
        "\n",
        "# Compile the model with CTC loss\n",
        "labels = Input(name='the_labels', shape=[None], dtype='float32')\n",
        "input_length = Input(name='input_length', shape=[1], dtype='int64')\n",
        "label_length = Input(name='label_length', shape=[1], dtype='int64')\n",
        "loss_out = Lambda(ctc_lambda_func, output_shape=(1,), name='ctc')([y_pred, labels, input_length, label_length])\n",
        "\n",
        "model = Model(inputs=[input_data, labels, input_length, label_length], outputs=loss_out)\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss={'ctc': lambda y_true, y_pred: y_pred})"
      ],
      "metadata": {
        "id": "tx4QsuMVH1ID"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Splitting Data and Defining Data Generator**"
      ],
      "metadata": {
        "id": "xeU2wc7FH3UP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code splits the dataset into training and validation sets and defines a data generator for batch processing."
      ],
      "metadata": {
        "id": "u_UpL16DH4qP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and validation sets\n",
        "X_train, X_val, y_train, y_val, input_length_train, input_length_val, label_length_train, label_length_val = train_test_split(X, y, input_lengths, label_lengths, test_size=0.2, random_state=42)\n",
        "\n",
        "def data_generator(X, y, input_lengths, label_lengths, batch_size=16):\n",
        "    while True:\n",
        "        for i in range(0, len(X), batch_size):\n",
        "            X_batch = X[i:i+batch_size]\n",
        "            y_batch = y[i:i+batch_size]\n",
        "            input_lengths_batch = input_lengths[i:i+batch_size]\n",
        "            label_lengths_batch = label_lengths[i:i+batch_size]\n",
        "            yield (\n",
        "                {\n",
        "                    'the_input': np.array(X_batch),\n",
        "                    'the_labels': np.array(y_batch),\n",
        "                    'input_length': np.array(input_lengths_batch),\n",
        "                    'label_length': np.array(label_lengths_batch)\n",
        "                },\n",
        "                {'ctc': np.zeros([len(X_batch)])}\n",
        "            )\n",
        "\n",
        "train_gen = data_generator(X_train, y_train, input_length_train, label_length_train, batch_size=16)\n",
        "val_gen = data_generator(X_val, y_val, input_length_val, label_length_val, batch_size=16)"
      ],
      "metadata": {
        "id": "IyNaDeebH5DP"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Defining Callbacks and Training the Model**"
      ],
      "metadata": {
        "id": "ac3Kb8xzH7Mr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code defines the callbacks for early stopping and model checkpointing, and trains the model."
      ],
      "metadata": {
        "id": "c8GnWGilH8nF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define callbacks\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "model_checkpoint = ModelCheckpoint('/content/asr_best_model.keras', monitor='val_loss', save_best_only=True)\n",
        "\n",
        "# Train the model\n",
        "model.fit(train_gen, steps_per_epoch=len(X_train) // 16, epochs=30, validation_data=val_gen, validation_steps=len(X_val) // 16, callbacks=[early_stopping, model_checkpoint])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4kEwLWlEH89v",
        "outputId": "6008998d-253e-4ea3-ff6d-3be58cca90a6"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "1218/1218 [==============================] - 153s 110ms/step - loss: 103.6746 - val_loss: 88.6871\n",
            "Epoch 2/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/saving/serialization_lib.py:403: UserWarning: The object being serialized includes a `lambda`. This is unsafe. In order to reload the object, you will have to pass `safe_mode=False` to the loading function. Please avoid using `lambda` in the future, and use named Python functions instead. This is the `lambda` being serialized: model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss={'ctc': lambda y_true, y_pred: y_pred})\n",
            "\n",
            "  return {key: serialize_keras_object(value) for key, value in obj.items()}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1218/1218 [==============================] - 130s 107ms/step - loss: 78.3142 - val_loss: 73.5646\n",
            "Epoch 3/30\n",
            "1218/1218 [==============================] - 125s 103ms/step - loss: 69.8039 - val_loss: 69.3648\n",
            "Epoch 4/30\n",
            "1218/1218 [==============================] - 125s 103ms/step - loss: 64.9113 - val_loss: 67.4747\n",
            "Epoch 5/30\n",
            "1218/1218 [==============================] - 125s 102ms/step - loss: 61.0730 - val_loss: 65.4924\n",
            "Epoch 6/30\n",
            "1218/1218 [==============================] - 126s 103ms/step - loss: 57.7974 - val_loss: 65.1898\n",
            "Epoch 7/30\n",
            "1218/1218 [==============================] - 126s 103ms/step - loss: 54.8173 - val_loss: 65.8492\n",
            "Epoch 8/30\n",
            "1218/1218 [==============================] - 124s 102ms/step - loss: 52.1247 - val_loss: 67.1747\n",
            "Epoch 9/30\n",
            "1218/1218 [==============================] - 123s 101ms/step - loss: 49.7280 - val_loss: 68.3288\n",
            "Epoch 10/30\n",
            "1218/1218 [==============================] - 123s 101ms/step - loss: 47.4697 - val_loss: 69.5886\n",
            "Epoch 11/30\n",
            "1218/1218 [==============================] - 123s 101ms/step - loss: 45.3362 - val_loss: 70.9945\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x79f90ad01690>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Saving the Model and Displaying Summary**"
      ],
      "metadata": {
        "id": "hh-rzK2QICgH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the final model\n",
        "model.save('/content/asr_model.keras')\n",
        "\n",
        "# Model summary\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cErG75d5IFeV",
        "outputId": "842a4392-d1dd-4027-e42a-0fa5b96f5fa8"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " the_input (InputLayer)      [(None, None, 40)]           0         []                            \n",
            "                                                                                                  \n",
            " masking (Masking)           (None, None, 40)             0         ['the_input[0][0]']           \n",
            "                                                                                                  \n",
            " bidirectional (Bidirection  (None, None, 512)            608256    ['masking[0][0]']             \n",
            " al)                                                                                              \n",
            "                                                                                                  \n",
            " batch_normalization (Batch  (None, None, 512)            2048      ['bidirectional[0][0]']       \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " bidirectional_1 (Bidirecti  (None, None, 512)            1574912   ['batch_normalization[0][0]'] \n",
            " onal)                                                                                            \n",
            "                                                                                                  \n",
            " batch_normalization_1 (Bat  (None, None, 512)            2048      ['bidirectional_1[0][0]']     \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " time_distributed (TimeDist  (None, None, 38)             19494     ['batch_normalization_1[0][0]'\n",
            " ributed)                                                           ]                             \n",
            "                                                                                                  \n",
            " activation (Activation)     (None, None, 38)             0         ['time_distributed[0][0]']    \n",
            "                                                                                                  \n",
            " the_labels (InputLayer)     [(None, None)]               0         []                            \n",
            "                                                                                                  \n",
            " input_length (InputLayer)   [(None, 1)]                  0         []                            \n",
            "                                                                                                  \n",
            " label_length (InputLayer)   [(None, 1)]                  0         []                            \n",
            "                                                                                                  \n",
            " ctc (Lambda)                (None, 1)                    0         ['activation[0][0]',          \n",
            "                                                                     'the_labels[0][0]',          \n",
            "                                                                     'input_length[0][0]',        \n",
            "                                                                     'label_length[0][0]']        \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 2206758 (8.42 MB)\n",
            "Trainable params: 2204710 (8.41 MB)\n",
            "Non-trainable params: 2048 (8.00 KB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Redefining Inference Model and Loading Weights**"
      ],
      "metadata": {
        "id": "sx00nNGrIHHp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code redefines the inference model and loads the best model weights."
      ],
      "metadata": {
        "id": "ITEPJXF1II6w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Redefine the inference model\n",
        "inference_model = Model(inputs=input_data, outputs=y_pred)\n",
        "\n",
        "# Load the weights from the best saved model\n",
        "inference_model.load_weights('/content/asr_best_model.keras')"
      ],
      "metadata": {
        "id": "tMCNImT4IIcU"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Predicting on a New Sample**"
      ],
      "metadata": {
        "id": "Nu_C2SHTILMU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code defines a function to predict on a new sample and tests the model on a specific sample index. Adjust the sample_index to test on different samples."
      ],
      "metadata": {
        "id": "nUQLPhabIPyi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to predict on a new sample\n",
        "def predict_sample(sample_index):\n",
        "    sample_features = X[sample_index]\n",
        "    sample_input_length = np.array([sample_features.shape[0]])\n",
        "\n",
        "    sample_features = np.expand_dims(sample_features, axis=0)\n",
        "    sample_input_length = np.array([sample_features.shape[1]], dtype=np.int32)\n",
        "\n",
        "    # Predict with beam search decoding\n",
        "    preds = inference_model.predict(sample_features)\n",
        "    decoded_pred = tf.keras.backend.ctc_decode(preds, input_length=sample_input_length, greedy=False, beam_width=10, top_paths=1)[0][0]\n",
        "    decoded_pred = tf.keras.backend.get_value(decoded_pred)\n",
        "\n",
        "    # Ensure decoded_pred is a 1D array\n",
        "    decoded_pred = decoded_pred.flatten()\n",
        "\n",
        "    # Convert the decoded prediction to text\n",
        "    predicted_text = ''.join([index_map[i] for i in decoded_pred if i != -1])\n",
        "\n",
        "    # Actual text from the dataset\n",
        "    actual_text = df.iloc[sample_index]['transcript']\n",
        "\n",
        "    print(f\"Predicted text: {predicted_text}\")\n",
        "    print(f\"Actual text: {actual_text}\")\n",
        "\n",
        "# Test the model on a new sample\n",
        "predict_sample(25)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F-IRUBToIN8-",
        "outputId": "cccc2498-e54c-4563-f8af-ccad7817dae2"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 25ms/step\n",
            "Predicted text: دس بردار ازیم کارا \n",
            "Actual text: دست بردار از این کارها\n"
          ]
        }
      ]
    }
  ]
}