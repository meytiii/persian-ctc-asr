{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import librosa\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, LSTM, Dense, Masking, TimeDistributed, Activation, Bidirectional, Lambda, Dropout\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "nu518WJhULTp"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download and unzip dataset\n",
        "import gdown\n",
        "\n",
        "url = 'https://drive.google.com/uc?id=1jyvhdZHn0s5Owkr21k5Ff-c96sIQLtEu'\n",
        "output = 'all_wav.zip'\n",
        "gdown.download(url, output, quiet=False)\n",
        "!unzip -q 'all_wav.zip' -d '/content/all_wav'\n",
        "\n",
        "url = 'https://drive.google.com/uc?id=1vqvn0F0YYhEFbzLgP9wJ36vyInUnO5b5'\n",
        "output = 'dataset.csv'\n",
        "gdown.download(url, output, quiet=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "id": "uofrgp6LUNj6",
        "outputId": "8dbfe58e-af8e-4410-ae1f-350ef92dc679"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1jyvhdZHn0s5Owkr21k5Ff-c96sIQLtEu\n",
            "From (redirected): https://drive.google.com/uc?id=1jyvhdZHn0s5Owkr21k5Ff-c96sIQLtEu&confirm=t&uuid=a5948018-46fc-4784-9157-8452ad93c4b4\n",
            "To: /content/all_wav.zip\n",
            "100%|██████████| 2.48G/2.48G [00:25<00:00, 96.0MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1vqvn0F0YYhEFbzLgP9wJ36vyInUnO5b5\n",
            "To: /content/dataset.csv\n",
            "100%|██████████| 2.87M/2.87M [00:00<00:00, 18.1MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'dataset.csv'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "df = pd.read_csv('/content/dataset.csv')\n",
        "df.head();"
      ],
      "metadata": {
        "id": "Fw_BV9l0UPMf"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "N7YOTR6pUDN6",
        "outputId": "8059a106-dd98-46e4-ac04-6200a0ef6aea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "609/609 [==============================] - 106s 141ms/step - loss: 96.8155 - val_loss: 87.9145\n",
            "Epoch 2/20\n",
            "609/609 [==============================] - 82s 135ms/step - loss: 86.4931 - val_loss: 79.8096\n",
            "Epoch 3/20\n",
            "609/609 [==============================] - 80s 131ms/step - loss: 82.0922 - val_loss: 75.6874\n",
            "Epoch 4/20\n",
            "609/609 [==============================] - 90s 148ms/step - loss: 79.2499 - val_loss: 73.0871\n",
            "Epoch 5/20\n",
            "609/609 [==============================] - 89s 146ms/step - loss: 77.2193 - val_loss: 71.2513\n",
            "Epoch 6/20\n",
            "609/609 [==============================] - 90s 147ms/step - loss: 75.5246 - val_loss: 69.7618\n",
            "Epoch 7/20\n",
            "609/609 [==============================] - 80s 130ms/step - loss: 74.2605 - val_loss: 68.4771\n",
            "Epoch 8/20\n",
            "609/609 [==============================] - 81s 133ms/step - loss: 73.0960 - val_loss: 67.8132\n",
            "Epoch 9/20\n",
            "609/609 [==============================] - 90s 149ms/step - loss: 72.1237 - val_loss: 66.7473\n",
            "Epoch 10/20\n",
            "609/609 [==============================] - 81s 134ms/step - loss: 71.2712 - val_loss: 66.2534\n",
            "Epoch 11/20\n",
            "609/609 [==============================] - 90s 148ms/step - loss: 70.5327 - val_loss: 65.8831\n",
            "Epoch 12/20\n",
            "609/609 [==============================] - 81s 134ms/step - loss: 69.9428 - val_loss: 65.3583\n",
            "Epoch 13/20\n",
            "609/609 [==============================] - 90s 147ms/step - loss: 69.3254 - val_loss: 64.6162\n",
            "Epoch 14/20\n",
            "609/609 [==============================] - 89s 145ms/step - loss: 68.8191 - val_loss: 63.9479\n",
            "Epoch 15/20\n",
            "609/609 [==============================] - 81s 133ms/step - loss: 68.2679 - val_loss: 63.7341\n",
            "Epoch 16/20\n",
            "609/609 [==============================] - 82s 134ms/step - loss: 67.7534 - val_loss: 63.2900\n",
            "Epoch 17/20\n",
            "609/609 [==============================] - 79s 130ms/step - loss: 67.4084 - val_loss: 62.8209\n",
            "Epoch 18/20\n",
            "609/609 [==============================] - 81s 133ms/step - loss: 66.9896 - val_loss: 62.5238\n",
            "Epoch 19/20\n",
            "609/609 [==============================] - 79s 130ms/step - loss: 66.5893 - val_loss: 61.9761\n",
            "Epoch 20/20\n",
            "609/609 [==============================] - 82s 135ms/step - loss: 66.2045 - val_loss: 61.7854\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 4s 4s/step\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "{{function_node __wrapped__CTCGreedyDecoder_device_/job:localhost/replica:0/task:0/device:CPU:0}} sequence_length is not a vector [Op:CTCGreedyDecoder] name: ",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-2391290da500>\u001b[0m in \u001b[0;36m<cell line: 161>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;31m# Predict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minference_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m \u001b[0mdecoded_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctc_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_input_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m \u001b[0mdecoded_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoded_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend.py\u001b[0m in \u001b[0;36mctc_decode\u001b[0;34m(y_pred, input_length, greedy, beam_width, top_paths)\u001b[0m\n\u001b[1;32m   7214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7215\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mgreedy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7216\u001b[0;31m         (decoded, log_prob) = tf.nn.ctc_greedy_decoder(\n\u001b[0m\u001b[1;32m   7217\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msequence_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7218\u001b[0m         )\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__CTCGreedyDecoder_device_/job:localhost/replica:0/task:0/device:CPU:0}} sequence_length is not a vector [Op:CTCGreedyDecoder] name: "
          ]
        }
      ],
      "source": [
        "# Update paths for WAV files\n",
        "df['wav_filename'] = df['wav_filename'].apply(lambda x: x.replace('./all_wav/', '/content/all_wav/all_wav/'))\n",
        "\n",
        "# Filter dataset to include only existing WAV files\n",
        "df = df[df['wav_filename'].apply(os.path.isfile)]\n",
        "\n",
        "# Character map for Persian characters\n",
        "char_map_str = \"\"\"\n",
        "' 0\n",
        "<SPACE> 1\n",
        "ا 2\n",
        "ب 3\n",
        "پ 4\n",
        "ت 5\n",
        "ث 6\n",
        "ج 7\n",
        "چ 8\n",
        "ح 9\n",
        "خ 10\n",
        "د 11\n",
        "ذ 12\n",
        "ر 13\n",
        "ز 14\n",
        "ژ 15\n",
        "س 16\n",
        "ش 17\n",
        "ص 18\n",
        "ض 19\n",
        "ط 20\n",
        "ظ 21\n",
        "ع 22\n",
        "غ 23\n",
        "ف 24\n",
        "ق 25\n",
        "ک 26\n",
        "گ 27\n",
        "ل 28\n",
        "م 29\n",
        "ن 30\n",
        "و 31\n",
        "ه 32\n",
        "ی 33\n",
        "، 34\n",
        "؟ 35\n",
        "\"\"\"\n",
        "char_map = {}\n",
        "index_map = {}\n",
        "for line in char_map_str.strip().split('\\n'):\n",
        "    ch, index = line.split()\n",
        "    char_map[ch] = int(index)\n",
        "    index_map[int(index)] = ch\n",
        "index_map[1] = ' '\n",
        "\n",
        "# Ensure space character is in char_map\n",
        "char_map[' '] = char_map['<SPACE>']\n",
        "\n",
        "# Audio processing functions\n",
        "def load_audio(file_path, sr=16000):\n",
        "    audio, _ = librosa.load(file_path, sr=sr)\n",
        "    return audio\n",
        "\n",
        "def extract_features(audio, n_mfcc=13, sr=16000):\n",
        "    mfcc_features = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=n_mfcc)\n",
        "    return mfcc_features.T\n",
        "\n",
        "# Prepare the dataset\n",
        "X = []\n",
        "y = []\n",
        "input_lengths = []\n",
        "label_lengths = []\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "    audio_path = row['wav_filename']\n",
        "    audio = load_audio(audio_path)\n",
        "    features = extract_features(audio)\n",
        "    X.append(features)\n",
        "    input_lengths.append(features.shape[0])\n",
        "    label = [char_map.get(c, char_map[' ']) for c in row['transcript']]\n",
        "    y.append(label)\n",
        "    label_lengths.append(len(label))\n",
        "\n",
        "if len(X) == 0 or len(y) == 0:\n",
        "    raise ValueError(\"No valid audio files were found. Please check the dataset and the paths.\")\n",
        "\n",
        "X = tf.keras.preprocessing.sequence.pad_sequences(X, padding='post', dtype='float32')\n",
        "y = tf.keras.preprocessing.sequence.pad_sequences(y, padding='post', value=-1)\n",
        "\n",
        "# Define the model\n",
        "input_data = Input(name='the_input', shape=(None, 13))\n",
        "masking_layer = Masking(mask_value=0.0)(input_data)\n",
        "bilstm_layer_1 = Bidirectional(LSTM(128, return_sequences=True))(masking_layer)\n",
        "dropout_1 = Dropout(0.5)(bilstm_layer_1)\n",
        "bilstm_layer_2 = Bidirectional(LSTM(128, return_sequences=True))(dropout_1)\n",
        "dropout_2 = Dropout(0.5)(bilstm_layer_2)\n",
        "time_dense = TimeDistributed(Dense(len(char_map) + 1))(dropout_2)\n",
        "y_pred = Activation('softmax', name='activation')(time_dense)\n",
        "\n",
        "# Define the CTC loss function\n",
        "def ctc_lambda_func(args):\n",
        "    y_pred, labels, input_length, label_length = args\n",
        "    return tf.keras.backend.ctc_batch_cost(labels, y_pred, input_length, label_length)\n",
        "\n",
        "# Compile the model with CTC loss\n",
        "labels = Input(name='the_labels', shape=[None], dtype='float32')\n",
        "input_length = Input(name='input_length', shape=[1], dtype='int64')\n",
        "label_length = Input(name='label_length', shape=[1], dtype='int64')\n",
        "loss_out = Lambda(ctc_lambda_func, output_shape=(1,), name='ctc')([y_pred, labels, input_length, label_length])\n",
        "\n",
        "model = Model(inputs=[input_data, labels, input_length, label_length], outputs=loss_out)\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(), loss={'ctc': lambda y_true, y_pred: y_pred})\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "X_train, X_val, y_train, y_val, input_length_train, input_length_val, label_length_train, label_length_val = train_test_split(X, y, input_lengths, label_lengths, test_size=0.2, random_state=42)\n",
        "\n",
        "# Data generator\n",
        "def data_generator(X, y, input_lengths, label_lengths, batch_size=32):\n",
        "    while True:\n",
        "        for i in range(0, len(X), batch_size):\n",
        "            X_batch = X[i:i+batch_size]\n",
        "            y_batch = y[i:i+batch_size]\n",
        "            input_lengths_batch = input_lengths[i:i+batch_size]\n",
        "            label_lengths_batch = label_lengths[i:i+batch_size]\n",
        "            yield (\n",
        "                {\n",
        "                    'the_input': np.array(X_batch),\n",
        "                    'the_labels': np.array(y_batch),\n",
        "                    'input_length': np.array(input_lengths_batch),\n",
        "                    'label_length': np.array(label_lengths_batch)\n",
        "                },\n",
        "                {'ctc': np.zeros([len(X_batch)])}\n",
        "            )\n",
        "\n",
        "train_gen = data_generator(X_train, y_train, input_length_train, label_length_train, batch_size=32)\n",
        "val_gen = data_generator(X_val, y_val, input_length_val, label_length_val, batch_size=32)\n",
        "\n",
        "steps_per_epoch = len(X_train) // 32\n",
        "validation_steps = len(X_val) // 32\n",
        "\n",
        "# Train the model\n",
        "model.fit(train_gen, steps_per_epoch=steps_per_epoch, epochs=20, validation_data=val_gen, validation_steps=validation_steps)\n",
        "\n",
        "# Save the model\n",
        "model.save('/content/asr_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Redefine the inference model\n",
        "inference_model = Model(inputs=input_data, outputs=y_pred)\n",
        "\n",
        "# Load the weights from the saved model\n",
        "inference_model.load_weights('/content/asr_model.h5')\n",
        "\n",
        "# Load a sample and predict\n",
        "sample_index = 0\n",
        "sample_features = X[sample_index]\n",
        "sample_input_length = np.array([sample_features.shape[0]])\n",
        "\n",
        "sample_features = np.expand_dims(sample_features, axis=0)\n",
        "sample_input_length = np.array([sample_features.shape[1]], dtype=np.int32)\n",
        "\n",
        "# Predict\n",
        "preds = inference_model.predict(sample_features)\n",
        "decoded_pred = tf.keras.backend.ctc_decode(preds, input_length=sample_input_length)[0][0]\n",
        "decoded_pred = tf.keras.backend.get_value(decoded_pred)\n",
        "\n",
        "# Ensure decoded_pred is a 1D array\n",
        "decoded_pred = decoded_pred.flatten()\n",
        "\n",
        "# Convert the decoded prediction to text\n",
        "predicted_text = ''.join([index_map[i] for i in decoded_pred if i != -1])\n",
        "\n",
        "# Actual text from the dataset\n",
        "actual_text = df.iloc[sample_index]['transcript']\n",
        "\n",
        "print(f\"Predicted text: {predicted_text}\")\n",
        "print(f\"Actual text: {actual_text}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vSyS0A-4UtVO",
        "outputId": "0f3df2b9-d095-4297-ac79-49cf4d244438"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 6s 6s/step\n",
            "Predicted text: تفاباتی کهدید بد\n",
            "Actual text: اتفاقاتی که ندیده بودم\n"
          ]
        }
      ]
    }
  ]
}